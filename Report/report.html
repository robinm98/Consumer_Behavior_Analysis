<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>report</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="report_files/libs/clipboard/clipboard.min.js"></script>
<script src="report_files/libs/quarto-html/quarto.js"></script>
<script src="report_files/libs/quarto-html/popper.min.js"></script>
<script src="report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="report_files/libs/quarto-html/anchor.min.js"></script>
<link href="report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="report_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="report_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
</head><body class="fullcontent">\usepackage{graphicx}
\newcommand{\coverTitle}[1]{\Huge\textbf{#1}\normalsize}
\newcommand{\coverAuthor}[1]{\large\textit{#1}\normalsize}
\newcommand{\coverInfo}[1]{\small\textbf{#1}\normalsize}
\newcommand{\coverDate}[1]{\small{#1}\normalsize}






<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<div style="page-break-after: always;"></div>
<p>Abstract: | The following machine learning project focuses on…</p>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<section id="overview-and-motivation" class="level2">
<h2 class="anchored" data-anchor-id="overview-and-motivation">Overview and Motivation</h2>
<p>In the fast-paced world of air travel, airlines face a dual challenge: maintaining operational efficiency while personalizing the travel experience for their passengers. Key aspects that greatly influence passenger satisfaction include baggage handling, preferred seating, and in-flight meals. Each of these elements represents significant opportunities for airlines to enhance customer experiences and optimize their ancillary services.</p>
<p>The project aims to harness machine learning to predict and analyze passengers’ choices regarding baggage, preferred seating, and in-flight meal options. By examining a range of influencing factors, such as trip duration and purpose, the project seeks to generate actionable insights that airlines can use to improve operational efficiency and tailor their services to individual customer preferences.</p>
<p>Our motivation stems from the logistical and customer service challenges faced by airlines when handling passengers’ preferences efficiently. Accurate prediction models will help airlines anticipate the demand for different services, from baggage needs to specific seating and meal preferences. This, in turn, will allow them to allocate resources more effectively and design better marketing strategies, enhancing customer satisfaction and maximizing revenue from ancillary services.</p>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>Our project’s dataset, titled “Airlines Booking” and compiled by <em>Anand Shaw</em>, is sourced from Kaggle. This CSV file encompasses anonymized airline booking records, capturing a diverse array of passenger information. The data includes specifics such as flight details, baggage choices, seating preferences, and in-flight meal options. With records from 50,000 users of the ticket booking portal across 14 distinct columns, this extensive dataset serves as the cornerstone for analyzing and discerning patterns in air traveler preferences. The dataset is available for access on Kaggle.</p>
</section>
<section id="related-work" class="level2">
<h2 class="anchored" data-anchor-id="related-work">Related Work</h2>
<p>Research on passenger preferences in air travel has highlighted several factors influencing travelers’ choices and behaviors, notably service offerings like baggage handling, seat selection, and in-flight meal preferences. Add-on revenues, such as those from baggage fees, preferred seating, and in-flight services, have become essential for airline profitability [1]. The growth in these revenue streams underscores their importance in airline strategies, as ancillary revenues accounted for about 18% of total airline revenue in 2022 [2].</p>
<p><strong>Baggage Preferences:</strong></p>
<p>Studies indicate that baggage fees and policies greatly affect customer behavior. Clear communication about baggage policies can influence booking decisions, and flexibility in these policies can enhance customer loyalty. Research shows that ancillary baggage fees impact travelers’ booking choices and willingness to pay [3], suggesting that transparent and adaptable baggage policies are crucial for maintaining customer satisfaction [3].</p>
<p><strong>Preferred Seating:</strong></p>
<p>Seat selection is critical for passenger comfort and satisfaction. Passengers value different seat attributes, such as proximity to exits, windows, or aisles, depending on their preferences. Research indicates that passengers are willing to pay extra for preferred seating, which underscores the importance of predictive models to cater to these preferences [4]. This willingness to pay highlights the revenue potential for airlines from charging for preferred seating [4].</p>
<p><strong>In-Flight Meals:</strong></p>
<p>The diversity in passengers’ dietary and cultural preferences necessitates a variety of meal options to meet these needs. Studies show that offering diverse in-flight meal options can significantly improve passenger satisfaction [5]. Airlines that effectively address these preferences can differentiate their services, leading to higher customer satisfaction and loyalty[5].</p>
<p>In summary, the research on passenger preferences in air travel highlights the critical role of add-on revenues such as baggage fees, preferred seating, and in-flight services. These elements not only significantly impact customer satisfaction but also contribute substantially to airline profitability. Clear communication and flexibility in baggage policies are essential for influencing booking decisions and enhancing customer loyalty. The willingness of passengers to pay extra for preferred seating and diverse in-flight meal options underscores the need for airlines to offer tailored services that meet diverse passenger preferences, ultimately driving higher customer satisfaction and loyalty.[1][2][3][4][5][6][7][8]</p>
</section>
<section id="research-questions" class="level2">
<h2 class="anchored" data-anchor-id="research-questions">Research questions</h2>
<p>Our study, “Modeling Passenger Preferences for Air Travel Upgrades,” focuses on developing predictive models to determine passenger choices for additional services during air travel and determining the response of the three upgrade classes simultaneously for each individual, employing multi-class modeling to capture the comprehensive preferences of passengers. The central research question explores the application of machine learning:</p>
<p><strong>How can machine learning models utilize passenger demographic and trip-specific data to predict preferences for air travel upgrades such as extra baggage, preferred seating, and in-flight meals?</strong></p>
<p>This question aims to uncover the potential of using various data points to accurately forecast which upgrades passengers are most likely to select, thereby enhancing personalized service delivery and operational efficiency.</p>
<p>In this report, we will start with exploring the structure of our data. Then, we will do an Exploratory Data Analysis (EDA) to understand the underlying structure and key patterns within the dataset. Following EDA, we will employ Unsupervised Learning techniques to uncover hidden structures and groupings in the data. Next, we will detail the Methodology of our Supervised Learning approaches, outlining the models used and the rationale behind their selection. We will then present the Results of our analysis, highlighting the performance of different models and key findings. Finally, we will conclude with a Conclusion, summarizing the insights gained and potential implications for airline operations and customer satisfaction.</p>
</section>
</section>
<section id="data-1" class="level1">
<h1>Data</h1>
<section id="sources" class="level2">
<h2 class="anchored" data-anchor-id="sources">Sources</h2>
<p>As previously introduced, our study utilizes the “Airlines Booking” dataset curated by Anand Shaw and hosted on Kaggle, with a records from 50,000 users of the ticket booking portal across 14 distinct columns. This dataset, provided in CSV format, will be used for our analysis aimed at modeling passenger preferences for air travel upgrades.</p>
</section>
<section id="description" class="level2">
<h2 class="anchored" data-anchor-id="description">Description</h2>
<p><strong><code>num_passengers</code></strong>: Indicates the total number of passengers traveling on the booking.</p>
<p><strong><code>sales_channel</code></strong>: Specifies the platform or method through which the booking was made (Internet or Mobile).</p>
<p><strong><code>trip_type</code></strong>: Describes the type of trip (e.g., Round Trip, One Way, Circle Trip).</p>
<p><strong><code>purchase_lead</code></strong>: Represents the number of days between the booking date and the travel date.</p>
<p><strong><code>length_of_stay</code></strong>: The number of days the passenger intends to stay at the destination.</p>
<p><strong><code>flight_hour</code></strong>: The hour of the day when the flight is scheduled to depart.</p>
<p><strong><code>flight_day</code></strong>: The day of the week on which the flight is scheduled.</p>
<p><strong><code>route</code></strong>: The flight route from origin to destination.</p>
<p><strong><code>booking_origin</code></strong>: The country from which the booking was made.</p>
<p><strong><code>wants_extra_baggage</code></strong>: A binary indicator (yes/no) if the passenger opted for extra baggage.</p>
<p><strong><code>wants_preferred_seat</code></strong>: A binary indicator (yes/no) if the passenger chose a preferred seating option during booking.</p>
<p><strong><code>wants_in_flight_meals</code></strong>: A binary indicator (yes/no) if the passenger requested in-flight meals.</p>
<p><strong><code>flight_duration</code></strong>: The total duration of the flight in hours.</p>
<p><strong><code>booking_complete</code></strong>: A flag indicating whether the booking was completed (yes/no).</p>
<p>The data has already been cleaned and is in good condition. However, further data processing will be conducted and explained in the Method’s section. This will involve removing any unnecessary data and encoding the data appropriately for use in our different models.</p>
</section>
</section>
<section id="exploratory-data-analysis-eda" class="level1">
<h1>Exploratory Data Analysis (EDA)</h1>
<p>EDA is a necessary step in understanding the underlying structure and patterns within our dataset. By employing various statistical and graphical techniques, EDA helps in identifying key relationships, trends, and anomalies that can inform further analysis and model development. In this section, we will explore the characteristics of our data on passenger preferences for air travel upgrades, focusing on how different features influence the choices for extra baggage, in-flight meals, and preferred seating. The insights gained from EDA will provide a solid foundation for building predictive models</p>
<section id="data-distribution-of-predictive-features-x" class="level2">
<h2 class="anchored" data-anchor-id="data-distribution-of-predictive-features-x">Data Distribution of Predictive Features (X)</h2>
<p>In this section, we will examine the data distribution of key predictive features (X) that influence passenger preferences for air travel upgrades. This analysis will help us understand how these features interact and contribute to predicting passenger choices for additional services.</p>
<p><strong>Distribution of Booking Origin</strong></p>
<p>The bar graph illustrates the distribution of booking origins across different continents. The booking origins are categorized into Africa, Americas, Asia, Europe, and Oceania.</p>
<p><em>Asia:</em> The highest number of bookings originate from Asia, with nearly 30,000 entries. This suggests a strong market presence or higher travel activity from this region.</p>
<p><em>Oceania:</em> The second-highest booking origin is Oceania, with around 20,000 entries, indicating significant travel activity from this continent.</p>
<p><em>Americas and Europe:</em> Both regions show relatively low booking counts, with Europe having slightly fewer entries than the Americas.</p>
<p><em>Africa and Unknown:</em> These categories have the least number of bookings, with counts close to zero, indicating minimal travel activity or possibly incomplete data for these regions.</p>
<p>Understanding the distribution of booking origins is crucial for airlines to tailor marketing strategies and resource allocation. Airlines can focus marketing efforts on regions with higher booking activity, such as Asia and Oceania, to maximize engagement and bookings. They can also develop specific offers and promotions for underrepresented regions like Africa and Europe to stimulate travel activity. Additionally, airlines can allocate resources and plan flight schedules based on demand from different regions to optimize operational efficiency. By leveraging these insights, airlines can enhance their strategic planning and improve overall customer satisfaction by addressing the specific needs and preferences of travelers from different regions.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><strong>Distribution of different trip types among passengers</strong></p>
<p>The bar graph illustrates the distribution of different trip types among passengers. The trip types include <code>CircleTrip</code>, <code>OneWay</code>, and <code>RoundTrip</code>. The data reveals a significant skew towards <code>RoundTrip</code> bookings, which dominate the dataset with nearly 50,000 instances. In contrast, <code>CircleTrip</code> and <code>OneWay</code> bookings are comparatively rare. ::: {.cell} ::: {.cell-output-display} <img src="report_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"> ::: :::</p>
<p><strong>Distribution of Sales Channel and Booking Completion</strong></p>
<p>The first plot shows the distribution of sales channels used by passengers for booking. The two categories are <code>Internet</code> and <code>Mobile</code>.</p>
<p><em>Internet:</em> The majority of bookings, over 40,000, are made through the internet. This indicates a strong preference for online booking among passengers.</p>
<p><em>Mobile:</em> A smaller segment, significantly less than 10,000, uses mobile devices for booking. This highlights a potential area for growth in mobile bookings.</p>
<p>The second plot illustrates the distribution of booking completion status, categorized as 0 (incomplete) and 1 (complete).</p>
<p><em>Incomplete Bookings (0):</em> The majority of instances, around 40,000, represent incomplete bookings. This suggests a high drop-off rate during the booking process.</p>
<p><em>Complete Bookings (1):</em> A smaller number, significantly less than 10,000, indicate completed bookings. This shows that a relatively small proportion of bookings are finalized.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><strong>Description of Distribution of Flight Day</strong></p>
<p>The bar graph shows the distribution of flight days, indicating how many flights occur on each day of the week.</p>
<p><em>Monday:</em> Has the highest number of flights, with counts slightly above 8,000. Thus, Monday is the busiest day for flights.</p>
<p><em>Tuesday and Wednesday:</em> These days also have high counts, slightly below 8,000, indicating significant travel activity. Thursday and Sunday: Both days show moderate flight activity, with counts around the 7,000 mark.</p>
<p><em>Friday:</em> Shows slightly lower flight counts compared to other weekdays, with counts around 6,500.</p>
<p><em>Saturday:</em> Has the lowest flight count, below 6,000, indicating it is the least busy day for flights. ::: {.cell} ::: {.cell-output-display} <img src="report_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"> ::: :::</p>
</section>
<section id="correlation-heatmap-relationship-between-variables-of-interest" class="level2">
<h2 class="anchored" data-anchor-id="correlation-heatmap-relationship-between-variables-of-interest">Correlation Heatmap: Relationship Between Variables of Interest</h2>
<p>The correlation heatmap visualizes the relationships between various variables related to passenger preferences for air travel upgrades. Each cell in the heatmap represents the correlation coefficient between two variables, with values ranging from -1 to 1. Darker shades of blue indicate a stronger positive correlation, while darker shades of red indicate a stronger negative correlation.</p>
<p>Key Observations:</p>
<p><strong>Length of Stay vs.&nbsp;Extra Baggage:</strong> There is a slight positive correlation, suggesting that passengers with longer stays tend to opt for extra baggage.</p>
<p><strong>Purchase Lead vs.&nbsp;Extra Baggage:</strong> There is a noticeable negative correlation, indicating that passengers who book further in advance are less likely to select extra baggage.</p>
<p><strong>Length of Stay vs.&nbsp;In-Flight Meals and Preferred Seats:</strong> Both show positive correlations, implying that longer stays increase the likelihood of choosing these services.</p>
<p><strong>Purchase Lead vs.&nbsp;Preferred Seats and In-Flight Meals:</strong> Both show negative correlations, meaning advance bookers are less likely to choose these additional services.</p>
<p>This heatmap provides a clear overview of how different factors, such as trip duration and booking behavior, influence passengers’ choices for ancillary services. Understanding these relationships can help airlines optimize their service offerings and improve customer satisfaction.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="target-variables-y-vs.-predictive-features-x" class="level2">
<h2 class="anchored" data-anchor-id="target-variables-y-vs.-predictive-features-x">Target Variables (Y) vs.&nbsp;Predictive Features (X)</h2>
<p>In this section, we examine the relationships between our target variables (Y) and various predictive features (X) to better understand passenger preferences for air travel upgrades. By analyzing these relationships, we aim to uncover patterns that can help predict the likelihood of passengers opting for additional services such as extra baggage, in-flight meals, and preferred seating.</p>
<p><strong>Number of Passengers and Service Preferences</strong></p>
<p>Extra Baggage Rates: Positive trend; larger groups more likely to want extra baggage.</p>
<p>In-Flight Meals Rates: Slight negative trend; larger groups less likely to want in-flight meals.</p>
<p>Preferred Seats Rates: Clear negative trend; larger groups less likely to choose preferred seats. ::: {.cell} ::: {.cell-output-display} <img src="report_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"> ::: :::</p>
<p><strong>Flight Duration and Service Preferences</strong></p>
<p>Extra Baggage Rates: Slight positive trend; longer flights slightly increase extra baggage demand.</p>
<p>In-Flight Meals Rates: Clear positive correlation; longer flights increase in-flight meal demand.</p>
<p>Preferred Seats Rates: Positive correlation; longer flights increase preferred seat selection. ::: {.cell} ::: {.cell-output-display} <img src="report_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"> ::: :::</p>
<p><strong>Purchase Lead Time and Service Preferences</strong></p>
<p>Extra Baggage Rates: Negative trend; early bookers less likely to want extra baggage.</p>
<p>In-Flight Meals Rates: Negative trend; early bookers less likely to want in-flight meals.</p>
<p>Preferred Seats Rates: Negative trend; early bookers less likely to select preferred seats. ::: {.cell} ::: {.cell-output-display} <img src="report_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"> ::: :::</p>
<p><strong>Length of Stay and Service Preferences</strong></p>
<p>Extra Baggage Rates: Slight decrease as length of stay increases.</p>
<p>In-Flight Meals Rates: Positive correlation; longer stays increase the likelihood of wanting in-flight meals.</p>
<p>Preferred Seats Rates: Positive correlation; longer stays increase the likelihood of choosing preferred seats. ::: {.cell} ::: {.cell-output-display} <img src="report_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"> ::: :::</p>
</section>
<section id="relationship-between-variables-of-interest" class="level2">
<h2 class="anchored" data-anchor-id="relationship-between-variables-of-interest">Relationship between variables of interest</h2>
<p>The first set of graphs compares the proportion of passengers wanting in-flight meals and preferred seats based on their baggage selection. The left graph indicates that passengers with extra baggage are more likely to want in-flight meals compared to those without extra baggage (0). Similarly, the right graph shows that a higher proportion of passengers with extra baggage (1) want preferred seat.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The second set of graphs examines the proportion of passengers wanting extra baggage and preferred seats based on their in-flight meal preferences. The left graph demonstrates that passengers who opt for in-flight meals (1) have a higher proportion of wanting extra baggage than those who do not want in-flight meals (0). The right graph reveals that passengers wanting in-flight meals are also more likely to choose preferred seats.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The third set of graphs explores the proportion of passengers wanting in-flight meals and extra baggage based on their seats preferences. The left graph shows that passengers opting for preferred seats (1) have a higher proportion of wanting extra baggage compared to those who do not (0). The right graph indicates that passengers with preffered seats are also more inclined to select in-flight meals.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This analysis highlights the interrelationships between ancillary services, suggesting that passengers who opt for one additional service are more likely to opt for others.</p>
</section>
</section>
<section id="unsupervised-learning" class="level1">
<h1>Unsupervised learning</h1>
<ul>
<li>Clustering and/or dimension reduction</li>
</ul>
</section>
<section id="method" class="level1">
<h1>Method</h1>
<section id="supervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h2>
<p>For our study on modeling passenger preferences for air travel upgrades, we selected three supervised machine learning techniques: logistic regression, random forest, and neural networks. Each of these models brings unique strengths and suitability for different aspects of our dataset.</p>
<p><strong>Logistic Regression</strong> is a fundamental technique in statistical modeling and machine learning, particularly adept at classification tasks, it represents our baseline model. In our study, we adapted logistic regression for multiclass classification to predict whether a passenger would opt for extra baggage or not, a preferred seat or not, and an in-flight meal or not. Logistic regression offers clear interpretability through the statistical significance of variables and their coefficients, allowing us to understand the influence of each predictor on the response variable.</p>
<p><strong>Random Forest</strong> is an ensemble learning technique that operates by building multiple decision trees and merging them together to obtain more accurate and stable predictions. It is particularly effective for handling datasets with complex structures and high dimensionality without requiring feature scaling. For multiclass classification issues, random forest can manage categorical variables and their interactions effectively, providing importance scores for each feature, which helps in interpreting the driving factors behind passenger preferences.</p>
<p><strong>Neural Networks</strong>, known for its deep learning capabilities, it is well-suited for capturing complex and nonlinear relationships. We utilized neural networks for multiclassification to simultaneously predict preferences across our categories of in-flight meals, seating, and baggage. Despite requiring more computational resources and being less interpretable, neural networks can model intricate patterns in large-scale data, potentially offering higher accuracy and generalization capabilities.</p>
<p>Together, these models encompass a broad spectrum of analytical capabilities, from basic statistical inference to complex pattern recognition. This diversified approach not only enhances the accuracy of our predictions but also enriches our understanding of the data’s underlying dynamics.</p>
<section id="data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing">Data Preprocessing</h3>
<p>Before applying the models, we preprocess the data to ensure it is in a suitable format for analysis. This involves removing columns that will not be of use in the models, encoding categorical variables, creating the necessary multiclass outcome variables, splitting the data into training and testing sets, and addressing class imbalances.</p>
<section id="removing-unneeded-columns" class="level4">
<h4 class="anchored" data-anchor-id="removing-unneeded-columns">Removing Unneeded Columns</h4>
<p>We remove columns that are not used in any models to streamline the data and reduce computational complexity. This step ensures that the models focus on relevant predictors and avoid overfitting due to irrelevant features or features that are not computationally efficient to create dummies for given their lack of importance.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Python code for Random Forest and Neural Networks</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.drop(columns<span class="op">=</span>[<span class="st">'route'</span>, <span class="st">'booking_origin'</span>, <span class="st">'departure'</span>, <span class="st">'arrival'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="handling-categorical-variables" class="level4">
<h4 class="anchored" data-anchor-id="handling-categorical-variables">Handling Categorical Variables</h4>
<p>Categorical variables such as <code>sales_channel</code>, <code>trip_type</code>, <code>flight_day</code>, and <code>continent</code> are central for our analysis. We transform these variables into a format suitable for modeling through one-hot encoding in python.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare categorical variables with OneHotEncoder</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>categorical_vars <span class="op">=</span> [<span class="st">'sales_channel'</span>, <span class="st">'trip_type'</span>, <span class="st">'flight_day'</span>, <span class="st">'continent'</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>ct <span class="op">=</span> ColumnTransformer([(<span class="st">'one_hot_encoder'</span>, OneHotEncoder(), categorical_vars)], remainder<span class="op">=</span><span class="st">'passthrough'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>data_processed <span class="op">=</span> ct.fit_transform(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="creating-the-outcome-combinations" class="level4">
<h4 class="anchored" data-anchor-id="creating-the-outcome-combinations">Creating the Outcome Combinations</h4>
<p>In our study, passengers can choose multiple services (<code>wants_extra_baggage</code>, <code>wants_preferred_seat</code>, and <code>wants_in_flight_meals</code>), and each combination of choices represents a distinct class. This creates a “power set” of outcome variables, forming all possible combinations as unique classes in a multiclass classification framework. We combine these outcome variables into a single multiclass target variable, encoding each unique combination (e.g., “000” for no preferences, “101” for extra baggage and an in-flight meal but not a preferred seat) into a distinct label. This allows the models to predict the exact combination of services a passenger is likely to choose, effectively modeling complex interactions between features.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the three binary target variables into a single multi-class label</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'combined_label'</span>] <span class="op">=</span> pd.factorize(data[<span class="st">'wants_extra_baggage'</span>].astype(<span class="bu">str</span>) <span class="op">+</span> </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                                      data[<span class="st">'wants_in_flight_meals'</span>].astype(<span class="bu">str</span>) <span class="op">+</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                                      data[<span class="st">'wants_preferred_seat'</span>].astype(<span class="bu">str</span>))[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="data-splitting" class="level4">
<h4 class="anchored" data-anchor-id="data-splitting">Data Splitting</h4>
<p>To ensure the reliability of our models, we split the data into training and testing sets. This division allows us to train the models on one subset and evaluate their performance on another, ensuring that the models generalize well to unseen data. We split at a 80/20 ratio to maintain a balance between training and testing data.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Python code for Random Forest and Neural Networks</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="addressing-class-imbalances" class="level4">
<h4 class="anchored" data-anchor-id="addressing-class-imbalances">Addressing Class Imbalances</h4>
<p>In our dataset, the classes are imbalanced, with some preferences being more prevalent than others. To address this issue, we used the technique of Synthetic Minority Over-sampling Technique (SMOTE) to balance the classes on our training set. This ensures that the models do not become biased towards the majority class and can make accurate predictions for all classes.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Note: The plot above shows the distribution of the target variable <code>wants_extra_baggage</code>. There is a clear imbalance towards cases whereby customers often purchased extra baggage.</em></p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Note: The plot above shows the distribution of the target variable <code>wants_in_flight_meals</code>. In this case the data was more evenly distrubuted so we decided to leave the classes as they were.</em></p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Note: The plot above shows the distribution of the target variable <code>wants_preferred_seat</code>. There is a clear imbalance towards cases whereby customers often did not purchase preferred seats.</em></p>
<p>To address the class imbalance, we used the <code>SMOTE</code> function from <code>imblearn</code>, which generates synthetic samples for the minority class to balance the class distribution.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SMOTE for Random Forest</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle class imbalance with SMOTE</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> smote.fit_resample(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="model-development-and-tuning" class="level3">
<h3 class="anchored" data-anchor-id="model-development-and-tuning">Model Development and Tuning</h3>
<p>This subsection outlines how each model is developed, including the initial setup, parameter tuning, and the specific adjustments made for each type.</p>
<section id="logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h4>
<p>The logistic regression model is developed using the <code>LogisticRegression</code> module from <code>sklearn</code> on python. Using the <code>multinomial</code> feature we are able to predict <code>wants_extra_baggage</code>, <code>wants_in_flight_meals</code>, and <code>wants_preferred_seat</code> simultaneously.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the LogisticRegression model</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'multinomial'</span>, solver<span class="op">=</span><span class="st">'sag'</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="random-forest" class="level4">
<h4 class="anchored" data-anchor-id="random-forest">Random Forest</h4>
<p>The Random Forest model is implemented using the <code>RandomForestClassifier</code> from the <code>scikit-learn</code> library in Python. For the implementation, we took advantage of its inherent capability to handle multiclass classification problems effectively.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the RandomForest model using the specified parameters</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">123</span>, n_estimators<span class="op">=</span><span class="dv">50</span>, max_features<span class="op">=</span><span class="va">None</span>, min_samples_split<span class="op">=</span><span class="dv">10</span>, min_samples_leaf<span class="op">=</span><span class="dv">5</span>, max_depth <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test data</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="neural-network" class="level4">
<h4 class="anchored" data-anchor-id="neural-network">Neural Network</h4>
<p>The Neural Network model was implemented using the <code>Keras</code> library in Python, which provides a high-level neural networks API that allows for easy and flexible model building.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Neural Network model using the specified parameters</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model(input_dim, activation<span class="op">=</span><span class="st">'relu'</span>, layers<span class="op">=</span><span class="dv">2</span>, dropout_rate<span class="op">=</span><span class="fl">0.5</span>, num_classes<span class="op">=</span><span class="dv">8</span>, nodes<span class="op">=</span><span class="dv">128</span>, l2_penalty<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(nodes, activation<span class="op">=</span>activation, input_dim<span class="op">=</span>input_dim, kernel_regularizer<span class="op">=</span>l2(l2_penalty)))</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(dropout_rate))</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, layers):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        model.add(Dense(nodes, activation<span class="op">=</span>activation, kernel_regularizer<span class="op">=</span>l2(l2_penalty)))</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        model.add(Dropout(dropout_rate))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the PRUNED best model found with GridSearchCV</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>best_model_params <span class="op">=</span> {</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'activation'</span>: <span class="st">'relu'</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'layers'</span>: <span class="dv">2</span>,</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dropout_rate'</span>: <span class="fl">0.5</span>,</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nodes'</span>: <span class="dv">128</span>,</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'l2_penalty'</span>: <span class="fl">0.01</span>,</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> create_model(input_dim<span class="op">=</span>X_train.shape[<span class="dv">1</span>], num_classes<span class="op">=</span>y.shape[<span class="dv">1</span>], <span class="op">**</span>best_model_params)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>, restore_best_weights<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train, batch_size<span class="op">=</span><span class="dv">32</span>, epochs<span class="op">=</span><span class="dv">20</span>, </span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>          verbose<span class="op">=</span><span class="dv">1</span>, validation_data<span class="op">=</span>(X_test, y_test), callbacks<span class="op">=</span>[early_stopping])</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test data</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>y_test_pred_prob <span class="op">=</span> model.predict(X_test)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> np.argmax(y_test_pred_prob, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>y_test_classes <span class="op">=</span> np.argmax(y_test, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="parameter-tuning" class="level4">
<h4 class="anchored" data-anchor-id="parameter-tuning">Parameter Tuning</h4>
<p>Parameter tuning and cross-validation are critical components in developing machine learning models, ensuring that the models not only fit the training data well but also generalize effectively to new, unseen data. Here, we’ll detail how these methodologies were applied across the logistic regression, random forest, and neural network models.</p>
<section id="gridsearchcv" class="level5">
<h5 class="anchored" data-anchor-id="gridsearchcv">GridsearchCV</h5>
<p>For all of our models, we used GridSearchCV from <code>sklearn</code> to find the optimal hyperparameters. This method exhaustively searches through a specified parameter grid to find the best combination of hyperparameters for each model. It also doubles as a cross-validation method, allowing us to evaluate the model’s performance on different subsets of the data, ensuring robust and generalized model selection.</p>
<p>For <strong>Logistic Regression</strong>, we tuned the <code>C</code> parameter and the <code>solver</code>. The C parameter is the inverse of regularization strength, where a smaller value indicates stronger regularization. The solver parameter determines the algorithm used in the optimization problem.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid Search for best parameters</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'solver'</span>: [<span class="st">'lbfgs'</span>, <span class="st">'liblinear'</span>, <span class="st">'sag'</span>, <span class="st">'saga'</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(LogisticRegression(multi_class<span class="op">=</span><span class="st">'multinomial'</span>, max_iter<span class="op">=</span><span class="dv">1000</span>), param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Best parameters</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> grid_search.best_params_</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best parameters from grid search:"</span>, best_params)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the LogisticRegression model with best parameters</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'multinomial'</span>, solver<span class="op">=</span>best_params[<span class="st">'solver'</span>], C<span class="op">=</span>best_params[<span class="st">'C'</span>], max_iter<span class="op">=</span><span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The GridSearchCV process identified <code>C=0.1</code> and <code>solver='sag'</code> as the optimal hyperparameters for our logistic regression model after performing 5-fold cross-validation. The choice of <code>C=0.1</code> indicates that a moderate level of regularization was most effective for this dataset, helping to prevent overfitting without under-penalizing the coefficients. The <code>sag</code> solver, which is efficient for large datasets and supports L2 regularization, was found to be the most suitable optimization algorithm for this multiclass classification problem.</p>
<p>For the <strong>Random Forest</strong> model, we tuned the <code>max_features</code>, <code>min_samples_split</code>, and <code>min_samples_leaf</code> parameters. The <code>max_features</code> parameter determines the number of features to consider when looking for the best split. The <code>min_samples_split</code> parameter specifies the minimum number of samples required to split an internal node, and the <code>min_samples_leaf</code> parameter defines the minimum number of samples required to be at a leaf node. These parameters are use to control the complexity and the depth of the individual trees within the forest, thereby influencing both the bias and variance of the model.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter grid focusing on fewer trees and tree complexity</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>, <span class="va">None</span>],  <span class="co"># Features considered for splitting at each leaf</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">10</span>, <span class="dv">20</span>],  <span class="co"># Minimum number of samples required to split an internal node</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">5</span>, <span class="dv">10</span>]  <span class="co"># Minimum number of samples required to be at a leaf node</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># GridSearchCV for parameter tuning</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities for the test set</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> grid_search.predict_proba(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The GridSearchCV process identified <code>max_features=None</code>, <code>min_samples_split=10</code>, and <code>min_samples_leaf=5</code> as the optimal hyperparameters for our Random Forest model after performing 10-fold cross-validation. The choice of <code>max_features=None</code> indicates that all features were considered when looking for the best split, allowing the model to potentially capture more complex patterns in the data. The parameters <code>min_samples_split=10</code> and <code>min_samples_leaf=5</code> help control the complexity of the trees by ensuring that splits and leaf nodes have a sufficient number of samples, reducing the risk of overfitting. <em>The <code>n_estimators</code> parameter was manually tested.</em></p>
<p>For the <strong>Neural Network</strong> model, we tuned the <code>layers</code>, <code>nodes</code>, and <code>activation</code>, leaving the other parameters set as <code>epochs = 20</code>, <code>batch_size = 32</code>, and <code>dropout_rate = 0.5</code>. The <code>layers</code> parameter determines the number of hidden layers in the network, while the <code>nodes</code> parameter specifies the number of neurons in each layer. The <code>activation</code> parameter defines the activation function used in the hidden layers, affecting how the model learns and represents complex patterns. The <code>epochs</code> and <code>batch_size</code> parameters control the training process, determining how many times the entire dataset is passed through the network and the number of samples per gradient update, respectively. The <code>dropout_rate</code> parameter helps prevent overfitting by randomly dropping neurons during training.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrap the model using KerasClassifier</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> y.shape[<span class="dv">1</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KerasClassifier(build_fn<span class="op">=</span>create_model, input_dim<span class="op">=</span>X_train.shape[<span class="dv">1</span>], verbose<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">'relu'</span>, layers<span class="op">=</span><span class="dv">1</span>, nodes<span class="op">=</span><span class="dv">64</span>, dropout_rate<span class="op">=</span><span class="fl">0.5</span>, num_classes<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter grid</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'layers'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'nodes'</span>: [<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>],</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'activation'</span>: [<span class="st">'relu'</span>, <span class="st">'tanh'</span>],</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'epochs'</span>: [<span class="dv">20</span>],</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'batch_size'</span>: [<span class="dv">32</span>],</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dropout_rate'</span>: [<span class="fl">0.5</span>]</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># GridSearchCV</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, verbose<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Best model from GridSearchCV</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, grid_search.best_params_)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Model:"</span>, best_model)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>y_pred_prob <span class="op">=</span> best_model.predict_proba(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The GridSearchCV process identified <code>activation='relu'</code>, <code>layers=2</code>, and <code>nodes=128</code> as the optimal hyperparameters for our Neural Network model after performing 5-fold cross-validation. The chosen configuration of <code>layers=2</code> and <code>nodes=128</code> ensures that the network has sufficient capacity to learn complex patterns in the data. The relu activation function was selected for its ability to introduce non-linearity while being computationally efficient. The dropout_rate=0.5 helps mitigate overfitting by preventing the network from becoming too reliant on specific neurons.</p>
<p><em>Note: Computational resources and time constraints limited the exhaustive search for optimal hyperparameters. In practice, it is essential to balance the trade-off between model performance and computational efficiency.</em></p>
</section>
</section>
<section id="overfitting" class="level4">
<h4 class="anchored" data-anchor-id="overfitting">Overfitting</h4>
<p>Overfitting occurs when a model learns the training data too well, capturing noise and irrelevant patterns that do not generalize to unseen data. To address overfitting, we sought to keep the training set accuracy and balanced accuracy within a few percentage points of each other during the model development process. Cross-validation and hyperparameter tuning aided, as well as some manual pruning of <code>n_estimators</code> and reduction in parameters available in the gridsearch.</p>
</section>
</section>
<section id="model-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation">Model Evaluation</h3>
<p>After training and tuning the models, we evaluated their performance on test data using metrics to assess their predictive capabilities. For each model, we calculated the following metrics:</p>
<ol type="1">
<li><p><strong>Accuracy</strong>: The proportion of correctly classified instances out of the total instances. It provides a general overview of the model’s performance.</p></li>
<li><p><strong>Balanced Accuracy</strong>: The average of recall obtained on each class. It is useful for large datasets as it considers the class distribution.</p></li>
<li><p><strong>Precision</strong>: The proportion of true positive predictions out of all positive predictions. It measures the model’s ability to avoid false positives.</p></li>
<li><p><strong>Recall</strong>: The proportion of true positive predictions out of all actual positives. It measures the model’s ability to capture all positive instances.</p></li>
</ol>
<p>The evaluation metrics for each model are summarized below:</p>
<div class="cell">
<div class="cell-output-display">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Accuracy</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Balanced.Accuracy</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Precision</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Recall</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: right;">0.2916</td>
<td style="text-align: right;">0.1978883</td>
<td style="text-align: right;">0.35</td>
<td style="text-align: right;">0.42</td>
<td style="text-align: left;">Random Forest</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">0.2153</td>
<td style="text-align: right;">0.2148545</td>
<td style="text-align: right;">0.36</td>
<td style="text-align: right;">0.33</td>
<td style="text-align: left;">Neural Network</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: right;">0.1913</td>
<td style="text-align: right;">0.2051088</td>
<td style="text-align: right;">0.29</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: left;">Logistic Regression</td>
</tr>
</tbody>
</table>


</div>
</div>
<section id="roc-curve-and-auc" class="level4">
<h4 class="anchored" data-anchor-id="roc-curve-and-auc">ROC Curve and AUC</h4>
<p><img src="../Figs/ROC_RF.png" class="img-fluid" alt="ROC Curve for Random Forest"> ### Interpretation of Results</p>
<ul>
<li>Interpretation of the model(s)</li>
</ul>
</section>
</section>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="random-forest-1" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-1">Random Forest</h2>
<p>The Random Forest model achieved an accuracy of 29.16% and a balanced accuracy of 19.79%. This indicates that while the model can correctly classify a significant portion of the instances, it struggles with class imbalances, as evidenced by the lower balanced accuracy. The precision of 35% suggests that the model makes relatively accurate positive predictions, while the recall of 42% indicates that it captures most of the actual positive cases. This balance between precision and recall demonstrates that the Random Forest model is reasonably effective in identifying true positives but still misses some.</p>
</section>
<section id="neural-network-1" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-1">Neural Network</h2>
<p>The Neural Network model achieved an accuracy of 21.53% and a balanced accuracy of 21.49%. The balanced accuracy being close to the overall accuracy suggests that the model is performing uniformly across different classes, though it still has room for improvement. With a precision of 36% and a recall of 33%, the neural network demonstrates a better ability to identify positive instances compared to logistic regression. However, its performance is still lower than that of the Random Forest model, indicating a need for further optimization or perhaps more training data.</p>
</section>
<section id="logistic-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-1">Logistic Regression</h2>
<p>The Logistic Regression model showed the lowest accuracy at 19.13% and a balanced accuracy of 20.51%. The precision and recall values are also lower, at 29% and 24%, respectively. This suggests that the logistic regression model, while interpretable and straightforward, is not as effective in capturing the complexities and interactions within the dataset compared to the Random Forest and Neural Network models. The lower performance might be due to the model’s linear nature, which may not adequately capture the nonlinear relationships present in the data.</p>
<p>Overall, the Random Forest model outperformed the other models in terms of accuracy, precision, and recall, indicating its relative success in handling complex, multiclass classification tasks. The Neural Network, while slightly less effective, still showed potential with a balanced approach to precision and recall.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>[1] OAG. (2023). Shaping Airline Retail: The Unstoppable Rise of Ancillaries. <em>Future of Travel</em> | OAG. OAG. <a href="https://www.oag.com/blog/shaping-airline-retail-unstoppable-rise-ancillaries">https://www.oag.com/blog/shaping-airline-retail-unstoppable-rise-ancillaries</a></p>
<p>[2] IdeaWorksCompany. (2023). Ancillary revenue increases 51% for 61 airlines in 2022. In <em>CarTrawler Yearbook of Ancillary Revenue</em> [Press-release]. CarTrawler. <a href="https://ideaworkscompany.com/wp-content/uploads/2023/09/Press-Release-177-Ancillary-Revenue-Yearbook.pdf">https://ideaworkscompany.com/wp-content/uploads/2023/09/Press-Release-177-Ancillary-Revenue-Yearbook.pdf</a></p>
<p>[3] Whitaker, B., Terzis, G., Soong, E., &amp; Yeh, W. (2005). Stated Preference as a Tool to Evaluate Airline Passenger Preferences and Priorities. <em>Transportation Research Record</em>, 1915(1), 55-61. <a href="https://doi.org/10.1177/0361198105191500107">https://doi.org/10.1177/0361198105191500107</a></p>
<p>[4] Kurtulmuşoğlu, F. B., Can, G. F., &amp; Tolon, M. (2016). A voice in the skies: Listening to airline passenger preferences. <em>Journal of Air Transport Management</em>, 57, 130-137.</p>
<p>[5] Chen, C. F., &amp; Wu, T. F. (2009). Exploring passenger preferences in airline service attributes: A note. <em>Journal of Air Transport Management</em>, 15(1), 52-53.</p>
<p>[6] Sun, X., Zheng, C., Wandelt, S., &amp; Zhang, A. (2024). Airline competition: A comprehensive review of recent research. <em>Journal of the Air Transport Research Society</em>, 100013.</p>
<p>[7] Bouwer, J., Esqué, A., &amp; Riedel, R. (2019, February 6). Leading from the front line: How airlines can boost ancillary revenues. <em>McKinsey &amp; Company</em>. <a href="https://www.mckinsey.com/industries/travel-logistics-and-infrastructure/our-insights/leading-from-the-front-line-how-airlines-can-boost-ancillary-revenues">https://www.mckinsey.com/industries/travel-logistics-and-infrastructure/our-insights/leading-from-the-front-line-how-airlines-can-boost-ancillary-revenues</a></p>
<p>[8] Airline profitability outlook strengthens. (2023, June 5). <a href="https://www.iata.org/en/pressroom/2023-releases/2023-06-05-01/">https://www.iata.org/en/pressroom/2023-releases/2023-06-05-01/</a></p>
<p>[9] ChatGPT, personal communication, May 15, 2024</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>